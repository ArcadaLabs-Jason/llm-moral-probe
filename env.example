# ============================================
# Moral Probe Configuration
# ============================================
# Copy this file to .env and update values:
#   cp .env.example .env
# ============================================

# --------------------------------------------
# ANTHROPIC API KEY (required for --score flag)
# --------------------------------------------
# Get yours at: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-api03-xxxxx

# --------------------------------------------
# VLLM SERVER URL
# --------------------------------------------
# Your Vast.ai tunnel URL (check Vast dashboard > Tunnels)
# Script auto-appends /v1/completions if needed
MORAL_PROBE_URL=https://your-tunnel-name.trycloudflare.com

# --------------------------------------------
# MODEL NAME  
# --------------------------------------------
# Must match exactly what you passed to vllm
# Examples:
#   meta-llama/Llama-3.1-8B
#   meta-llama/Llama-3.1-70B
#   Qwen/Qwen2.5-32B
#   mistralai/Ministral-3-14B-Base-2512
MORAL_PROBE_MODEL=meta-llama/Llama-3.1-8B
